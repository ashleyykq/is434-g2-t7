{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7650216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f838878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postUrl</th>\n",
       "      <th>description</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>likedByViewer</th>\n",
       "      <th>isSidecar</th>\n",
       "      <th>type</th>\n",
       "      <th>profileUrl</th>\n",
       "      <th>username</th>\n",
       "      <th>...</th>\n",
       "      <th>taggedFullName6</th>\n",
       "      <th>taggedUsername6</th>\n",
       "      <th>taggedFullName7</th>\n",
       "      <th>taggedUsername7</th>\n",
       "      <th>taggedFullName8</th>\n",
       "      <th>taggedUsername8</th>\n",
       "      <th>taggedFullName9</th>\n",
       "      <th>taggedUsername9</th>\n",
       "      <th>taggedFullName10</th>\n",
       "      <th>taggedUsername10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.instagram.com/p/Cbwu4mjlNt4/</td>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-03-31T08:26:20.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.instagram.com/p/CbuAnmklF2f/</td>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-03-30T07:03:35.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.instagram.com/p/Cbd_8YRln_a/</td>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-03-24T01:49:50.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.instagram.com/p/Cbd_8YRln_a/</td>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-03-24T01:49:50.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.instagram.com/p/Cbd_8YRln_a/</td>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2022-03-24T01:49:50.000Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>https://www.instagram.com/p/Bl7jD-YAYCw/</td>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-08-01T08:59:24.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>https://www.instagram.com/p/Bl7jAFDAJVr/</td>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-08-01T08:58:52.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>https://www.instagram.com/p/Bl7i90WA_yH/</td>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-08-01T08:58:33.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>https://www.instagram.com/p/Bl7i7npATR7/</td>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-08-01T08:58:15.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>https://www.instagram.com/p/Bl7i4qlA_fG/</td>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-08-01T08:57:51.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photo</td>\n",
       "      <td>https://www.instagram.com/sgsmuscis</td>\n",
       "      <td>sgsmuscis</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       postUrl  \\\n",
       "0     https://www.instagram.com/p/Cbwu4mjlNt4/   \n",
       "1     https://www.instagram.com/p/CbuAnmklF2f/   \n",
       "2     https://www.instagram.com/p/Cbd_8YRln_a/   \n",
       "3     https://www.instagram.com/p/Cbd_8YRln_a/   \n",
       "4     https://www.instagram.com/p/Cbd_8YRln_a/   \n",
       "...                                        ...   \n",
       "1048  https://www.instagram.com/p/Bl7jD-YAYCw/   \n",
       "1049  https://www.instagram.com/p/Bl7jAFDAJVr/   \n",
       "1050  https://www.instagram.com/p/Bl7i90WA_yH/   \n",
       "1051  https://www.instagram.com/p/Bl7i7npATR7/   \n",
       "1052  https://www.instagram.com/p/Bl7i4qlA_fG/   \n",
       "\n",
       "                                            description  commentCount  \\\n",
       "0     SMU SCIS alumnus Quan Heng Lim discussed the c...             0   \n",
       "1     Have you ever wondered how a website like YouT...             0   \n",
       "2     Over the past weekend, Whitehat Society (@smuw...             0   \n",
       "3     Over the past weekend, Whitehat Society (@smuw...             0   \n",
       "4     Over the past weekend, Whitehat Society (@smuw...             0   \n",
       "...                                                 ...           ...   \n",
       "1048                                    #ComputingatSMU             0   \n",
       "1049                                    #ComputingatSMU             0   \n",
       "1050                                    #ComputingatSMU             0   \n",
       "1051                                    #ComputingatSMU             0   \n",
       "1052                                    #ComputingatSMU             0   \n",
       "\n",
       "      likeCount                   pubDate likedByViewer isSidecar   type  \\\n",
       "0           3.0  2022-03-31T08:26:20.000Z         False     False  Photo   \n",
       "1           3.0  2022-03-30T07:03:35.000Z         False     False  Photo   \n",
       "2          22.0  2022-03-24T01:49:50.000Z         False      True  Photo   \n",
       "3          22.0  2022-03-24T01:49:50.000Z         False      True  Photo   \n",
       "4          22.0  2022-03-24T01:49:50.000Z         False      True  Photo   \n",
       "...         ...                       ...           ...       ...    ...   \n",
       "1048        1.0  2018-08-01T08:59:24.000Z           NaN       NaN  Photo   \n",
       "1049        2.0  2018-08-01T08:58:52.000Z           NaN       NaN  Photo   \n",
       "1050        2.0  2018-08-01T08:58:33.000Z           NaN       NaN  Photo   \n",
       "1051        3.0  2018-08-01T08:58:15.000Z           NaN       NaN  Photo   \n",
       "1052        2.0  2018-08-01T08:57:51.000Z           NaN       NaN  Photo   \n",
       "\n",
       "                               profileUrl   username  ... taggedFullName6  \\\n",
       "0     https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "1     https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "2     https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "3     https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "4     https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "...                                   ...        ...  ...             ...   \n",
       "1048  https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "1049  https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "1050  https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "1051  https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "1052  https://www.instagram.com/sgsmuscis  sgsmuscis  ...             NaN   \n",
       "\n",
       "     taggedUsername6 taggedFullName7 taggedUsername7 taggedFullName8  \\\n",
       "0                NaN             NaN             NaN             NaN   \n",
       "1                NaN             NaN             NaN             NaN   \n",
       "2                NaN             NaN             NaN             NaN   \n",
       "3                NaN             NaN             NaN             NaN   \n",
       "4                NaN             NaN             NaN             NaN   \n",
       "...              ...             ...             ...             ...   \n",
       "1048             NaN             NaN             NaN             NaN   \n",
       "1049             NaN             NaN             NaN             NaN   \n",
       "1050             NaN             NaN             NaN             NaN   \n",
       "1051             NaN             NaN             NaN             NaN   \n",
       "1052             NaN             NaN             NaN             NaN   \n",
       "\n",
       "     taggedUsername8  taggedFullName9 taggedUsername9 taggedFullName10  \\\n",
       "0                NaN              NaN             NaN              NaN   \n",
       "1                NaN              NaN             NaN              NaN   \n",
       "2                NaN              NaN             NaN              NaN   \n",
       "3                NaN              NaN             NaN              NaN   \n",
       "4                NaN              NaN             NaN              NaN   \n",
       "...              ...              ...             ...              ...   \n",
       "1048             NaN              NaN             NaN              NaN   \n",
       "1049             NaN              NaN             NaN              NaN   \n",
       "1050             NaN              NaN             NaN              NaN   \n",
       "1051             NaN              NaN             NaN              NaN   \n",
       "1052             NaN              NaN             NaN              NaN   \n",
       "\n",
       "     taggedUsername10  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "1048              NaN  \n",
       "1049              NaN  \n",
       "1050              NaN  \n",
       "1051              NaN  \n",
       "1052              NaN  \n",
       "\n",
       "[1053 rows x 39 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv(\"sgsmuscis posts.csv\")\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f613c95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reposted @smu.libraries ••••• How much do you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Using games as part of a mock seminar for Cath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>At AJC’s University Symposium, Hady fielded fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Getting ready for students at the Education Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>It happened one night.\\n#SMUMetamorphosis #smu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>#ComputingatSMU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description\n",
       "0     SMU SCIS alumnus Quan Heng Lim discussed the c...\n",
       "1     Have you ever wondered how a website like YouT...\n",
       "2     Over the past weekend, Whitehat Society (@smuw...\n",
       "8     Reposted @smu.libraries ••••• How much do you ...\n",
       "9     Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...\n",
       "...                                                 ...\n",
       "1040  Using games as part of a mock seminar for Cath...\n",
       "1041  At AJC’s University Symposium, Hady fielded fr...\n",
       "1042  Getting ready for students at the Education Fa...\n",
       "1043  It happened one night.\\n#SMUMetamorphosis #smu...\n",
       "1044                                    #ComputingatSMU\n",
       "\n",
       "[504 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_posts = posts[[\"description\"]]\n",
    "filtered_posts = filtered_posts.drop_duplicates()\n",
    "filtered_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5c12e",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd26653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "      <td>smu scis alumnus quan heng lim discussed the c...</td>\n",
       "      <td>[(SMU, n), (SCIS, n), (alumnus, v), (Quan, n),...</td>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discuss cyber...</td>\n",
       "      <td>[SMU, SCIS, alumnus, Quan, Heng, Lim, discuss,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "      <td>have you ever wondered how a website like yout...</td>\n",
       "      <td>[(ever, r), (wondered, v), (website, n), (like...</td>\n",
       "      <td>ever wonder website like YouTube know want l...</td>\n",
       "      <td>[ever, wonder, website, like, YouTube, know, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>over the past weekend whitehat society smuwhit...</td>\n",
       "      <td>[(past, a), (weekend, n), (Whitehat, None), (S...</td>\n",
       "      <td>past weekend Whitehat Society smuwhitehats o...</td>\n",
       "      <td>[past, weekend, Whitehat, Society, smuwhitehat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reposted @smu.libraries ••••• How much do you ...</td>\n",
       "      <td>reposted smu libraries how much do you know ab...</td>\n",
       "      <td>[(Reposted, v), (smu, a), (libraries, v), (muc...</td>\n",
       "      <td>Reposted smu libraries much know plastic pol...</td>\n",
       "      <td>[Reposted, smu, libraries, much, know, plastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...</td>\n",
       "      <td>since smu s dato kho hui meng career centre an...</td>\n",
       "      <td>[(Since, None), (SMU, n), (Dato, n), (Kho, n),...</td>\n",
       "      <td>Since SMU Dato Kho Hui Meng Career Centre an...</td>\n",
       "      <td>[Since, SMU, Dato, Kho, Hui, Meng, Career, Cen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  SMU SCIS alumnus Quan Heng Lim discussed the c...   \n",
       "1  Have you ever wondered how a website like YouT...   \n",
       "2  Over the past weekend, Whitehat Society (@smuw...   \n",
       "8  Reposted @smu.libraries ••••• How much do you ...   \n",
       "9  Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  smu scis alumnus quan heng lim discussed the c...   \n",
       "1  have you ever wondered how a website like yout...   \n",
       "2  over the past weekend whitehat society smuwhit...   \n",
       "8  reposted smu libraries how much do you know ab...   \n",
       "9  since smu s dato kho hui meng career centre an...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(SMU, n), (SCIS, n), (alumnus, v), (Quan, n),...   \n",
       "1  [(ever, r), (wondered, v), (website, n), (like...   \n",
       "2  [(past, a), (weekend, n), (Whitehat, None), (S...   \n",
       "8  [(Reposted, v), (smu, a), (libraries, v), (muc...   \n",
       "9  [(Since, None), (SMU, n), (Dato, n), (Kho, n),...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0    SMU SCIS alumnus Quan Heng Lim discuss cyber...   \n",
       "1    ever wonder website like YouTube know want l...   \n",
       "2    past weekend Whitehat Society smuwhitehats o...   \n",
       "8    Reposted smu libraries much know plastic pol...   \n",
       "9    Since SMU Dato Kho Hui Meng Career Centre an...   \n",
       "\n",
       "                                        lemma_tokens  \n",
       "0  [SMU, SCIS, alumnus, Quan, Heng, Lim, discuss,...  \n",
       "1  [ever, wonder, website, like, YouTube, know, w...  \n",
       "2  [past, weekend, Whitehat, Society, smuwhitehat...  \n",
       "8  [Reposted, smu, libraries, much, know, plastic...  \n",
       "9  [Since, SMU, Dato, Kho, Hui, Meng, Career, Cen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "#     print(text)\n",
    "# Removes all special characters and numericals leaving the alphabets\n",
    "#     text = re.sub(r'https?://\\S+', \"\")\n",
    "#     text = re.sub('\\\\n', '')\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^A-Za-z]+', ' ', str(text))\n",
    "    text = re.sub(r'http\\S+', '', str(text))\n",
    "    emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in str(text).split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Cleaning the text in the Text column\n",
    "filtered_posts['cleaned'] = filtered_posts['description'].apply(clean)\n",
    "filtered_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b74c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'nbsp', 'schoolofinformationsystems', 'smuscis', 'smu', 'sis', 'computingatsmu', 'sgsmu', 'smusis', 'q', 'ly', 'bit', 'sg', 'like', 'singapore', 'school', 'university', 'scis', 'year', 'student', 'smartcitymanagement', 'computerscience', 'informationsystems']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "      <td>smu scis alumnus quan heng lim discussed the c...</td>\n",
       "      <td>[(alumnus, None), (quan, a), (heng, n), (lim, ...</td>\n",
       "      <td>alumnus quan heng lim discuss cyber security...</td>\n",
       "      <td>[alumnus, quan, heng, lim, discuss, cyber, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "      <td>have you ever wondered how a website like yout...</td>\n",
       "      <td>[(ever, r), (wondered, v), (website, n), (yout...</td>\n",
       "      <td>ever wonder website youtube know want e comm...</td>\n",
       "      <td>[ever, wonder, website, youtube, know, want, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>over the past weekend whitehat society smuwhit...</td>\n",
       "      <td>[(past, a), (weekend, n), (whitehat, None), (s...</td>\n",
       "      <td>past weekend whitehat society smuwhitehats o...</td>\n",
       "      <td>[past, weekend, whitehat, society, smuwhitehat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reposted @smu.libraries ••••• How much do you ...</td>\n",
       "      <td>reposted smu libraries how much do you know ab...</td>\n",
       "      <td>[(reposted, v), (libraries, v), (much, a), (kn...</td>\n",
       "      <td>reposted libraries much know plastic polluti...</td>\n",
       "      <td>[reposted, libraries, much, know, plastic, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...</td>\n",
       "      <td>since smu s dato kho hui meng career centre an...</td>\n",
       "      <td>[(since, None), (dato, n), (kho, n), (hui, n),...</td>\n",
       "      <td>since dato kho hui meng career centre annual...</td>\n",
       "      <td>[since, dato, kho, hui, meng, career, centre, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  SMU SCIS alumnus Quan Heng Lim discussed the c...   \n",
       "1  Have you ever wondered how a website like YouT...   \n",
       "2  Over the past weekend, Whitehat Society (@smuw...   \n",
       "8  Reposted @smu.libraries ••••• How much do you ...   \n",
       "9  Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  smu scis alumnus quan heng lim discussed the c...   \n",
       "1  have you ever wondered how a website like yout...   \n",
       "2  over the past weekend whitehat society smuwhit...   \n",
       "8  reposted smu libraries how much do you know ab...   \n",
       "9  since smu s dato kho hui meng career centre an...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(alumnus, None), (quan, a), (heng, n), (lim, ...   \n",
       "1  [(ever, r), (wondered, v), (website, n), (yout...   \n",
       "2  [(past, a), (weekend, n), (whitehat, None), (s...   \n",
       "8  [(reposted, v), (libraries, v), (much, a), (kn...   \n",
       "9  [(since, None), (dato, n), (kho, n), (hui, n),...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0    alumnus quan heng lim discuss cyber security...   \n",
       "1    ever wonder website youtube know want e comm...   \n",
       "2    past weekend whitehat society smuwhitehats o...   \n",
       "8    reposted libraries much know plastic polluti...   \n",
       "9    since dato kho hui meng career centre annual...   \n",
       "\n",
       "                                        lemma_tokens  \n",
       "0  [alumnus, quan, heng, lim, discuss, cyber, sec...  \n",
       "1  [ever, wonder, website, youtube, know, want, e...  \n",
       "2  [past, weekend, whitehat, society, smuwhitehat...  \n",
       "8  [reposted, libraries, much, know, plastic, pol...  \n",
       "9  [since, dato, kho, hui, meng, career, centre, ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['nbsp', 'schoolofinformationsystems', 'smuscis', 'smu', 'sis', 'computingatsmu', 'sgsmu', 'smusis', 'q', 'ly', 'bit'])\n",
    "stop_words.extend(['sg', 'like', 'singapore', 'school', 'university', 'scis', 'year', 'student', 'smartcitymanagement', 'computerscience', 'informationsystems'])\n",
    "print(stop_words)\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stop_words):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "filtered_posts['POS tagged'] = filtered_posts['cleaned'].apply(token_stop_pos)\n",
    "filtered_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cbc4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('past', 'a'), ('weekend', 'n'), ('whitehat', None), ('society', 'n'), ('smuwhitehats', 'n'), ('organised', 'v'), ('annual', 'a'), ('flagship', 'n'), ('event', 'n'), ('whitehacks', 'n'), ('held', 'v'), ('across', None), ('span', 'n'), ('days', 'n'), ('march', 'n'), ('iteration', 'n'), ('students', 'n'), ('various', 'a'), ('junior', 'a'), ('colleges', 'n'), ('high', 'a'), ('schools', 'n'), ('joining', 'v'), ('us', None), ('explore', 'v'), ('learn', 'v'), ('cybersecurity', 'n'), ('day', 'n'), ('commenced', 'v'), ('opening', 'n'), ('address', 'n'), ('dean', 'n'), ('computing', 'v'), ('information', 'n'), ('systems', 'n'), ('dr', 'n'), ('pang', 'n'), ('hwee', 'n'), ('hwa', 'n'), ('following', 'v'), ('students', 'n'), ('got', 'v'), ('learn', 'v'), ('various', 'a'), ('opportunities', 'n'), ('interact', 'n'), ('various', 'a'), ('industry', 'n'), ('professionals', 'n'), ('centre', 'n'), ('strategic', 'a'), ('infocomm', 'n'), ('technologies', 'n'), ('csit', 'v'), ('govtech', 'n'), ('cyber', 'v'), ('security', 'n'), ('agency', 'n'), ('csa', 'n'), ('zoom', 'n'), ('sharing', 'n'), ('sessions', 'n'), ('discord', 'n'), ('villages', 'v'), ('highlight', 'n'), ('event', 'n'), ('hour', 'n'), ('capture', 'n'), ('flag', 'n'), ('competition', 'n'), ('held', 'v'), ('day', 'n'), ('began', 'v'), ('flurry', 'n'), ('challenges', 'n'), ('first', 'r'), ('blooded', 'v'), ('various', 'a'), ('teams', 'n'), ('within', None), ('first', 'a'), ('hour', 'n'), ('alone', 'r'), ('competition', 'n'), ('remained', 'v'), ('intense', 'a'), ('throughout', None), ('entire', 'a'), ('duration', 'n'), ('heartened', 'v'), ('see', 'v'), ('participating', 'v'), ('teams', 'n'), ('giving', 'v'), ('battled', 'v'), ('top', 'a'), ('prizes', 'n'), ('would', None), ('also', 'r'), ('express', 'v'), ('heartfelt', 'n'), ('thanks', 'n'), ('sponsors', 'n'), ('centre', 'v'), ('strategic', 'a'), ('infocomm', 'n'), ('technologies', 'n'), ('csit', 'v'), ('govtech', 'n'), ('cyber', 'v'), ('security', 'n'), ('agency', 'n'), ('csa', 'n'), ('mandiant', 'n'), ('supporting', 'v'), ('us', None), ('event', 'n'), ('would', None), ('also', 'r'), ('thank', 'v'), ('kenneth', 'n'), ('alt', 'a'), ('tab', 'n'), ('labs', 'n'), ('helping', 'v'), ('us', None), ('manage', 'v'), ('ctf', 'n'), ('infrastructure', 'n'), ('throughout', None), ('entire', 'a'), ('duration', 'n'), ('competition', 'n'), ('thank', 'n'), ('everyone', 'n'), ('look', 'v'), ('forward', 'r'), ('seeing', 'v'), ('next', 'a'), ('digitaltransformation', 'n'), ('sgsmuscis', 'n')]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_posts['POS tagged'].iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34e95f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "      <td>smu scis alumnus quan heng lim discussed the c...</td>\n",
       "      <td>[(alumnus, None), (quan, a), (heng, n), (lim, ...</td>\n",
       "      <td>alumnus quan heng lim discuss cyber security...</td>\n",
       "      <td>[alumnus, quan, heng, lim, discuss, cyber, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "      <td>have you ever wondered how a website like yout...</td>\n",
       "      <td>[(ever, r), (wondered, v), (website, n), (yout...</td>\n",
       "      <td>ever wonder website youtube know want e comm...</td>\n",
       "      <td>[ever, wonder, website, youtube, know, want, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>over the past weekend whitehat society smuwhit...</td>\n",
       "      <td>[(past, a), (weekend, n), (whitehat, None), (s...</td>\n",
       "      <td>past weekend whitehat society smuwhitehats o...</td>\n",
       "      <td>[past, weekend, whitehat, society, smuwhitehat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reposted @smu.libraries ••••• How much do you ...</td>\n",
       "      <td>reposted smu libraries how much do you know ab...</td>\n",
       "      <td>[(reposted, v), (libraries, v), (much, a), (kn...</td>\n",
       "      <td>reposted libraries much know plastic polluti...</td>\n",
       "      <td>[reposted, libraries, much, know, plastic, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...</td>\n",
       "      <td>since smu s dato kho hui meng career centre an...</td>\n",
       "      <td>[(since, None), (dato, n), (kho, n), (hui, n),...</td>\n",
       "      <td>since dato kho hui meng career centre annual...</td>\n",
       "      <td>[since, dato, kho, hui, meng, career, centre, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  SMU SCIS alumnus Quan Heng Lim discussed the c...   \n",
       "1  Have you ever wondered how a website like YouT...   \n",
       "2  Over the past weekend, Whitehat Society (@smuw...   \n",
       "8  Reposted @smu.libraries ••••• How much do you ...   \n",
       "9  Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  smu scis alumnus quan heng lim discussed the c...   \n",
       "1  have you ever wondered how a website like yout...   \n",
       "2  over the past weekend whitehat society smuwhit...   \n",
       "8  reposted smu libraries how much do you know ab...   \n",
       "9  since smu s dato kho hui meng career centre an...   \n",
       "\n",
       "                                          POS tagged  \\\n",
       "0  [(alumnus, None), (quan, a), (heng, n), (lim, ...   \n",
       "1  [(ever, r), (wondered, v), (website, n), (yout...   \n",
       "2  [(past, a), (weekend, n), (whitehat, None), (s...   \n",
       "8  [(reposted, v), (libraries, v), (much, a), (kn...   \n",
       "9  [(since, None), (dato, n), (kho, n), (hui, n),...   \n",
       "\n",
       "                                               Lemma  \\\n",
       "0    alumnus quan heng lim discuss cyber security...   \n",
       "1    ever wonder website youtube know want e comm...   \n",
       "2    past weekend whitehat society smuwhitehats o...   \n",
       "8    reposted libraries much know plastic polluti...   \n",
       "9    since dato kho hui meng career centre annual...   \n",
       "\n",
       "                                        lemma_tokens  \n",
       "0  [alumnus, quan, heng, lim, discuss, cyber, sec...  \n",
       "1  [ever, wonder, website, youtube, know, want, e...  \n",
       "2  [past, weekend, whitehat, society, smuwhitehat...  \n",
       "8  [reposted, libraries, much, know, plastic, pol...  \n",
       "9  [since, dato, kho, hui, meng, career, centre, ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "filtered_posts['Lemma'] = filtered_posts['POS tagged'].apply(lemmatize)\n",
    "filtered_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ebe83b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>POS tagged</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>lemma_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMU SCIS alumnus Quan Heng Lim discussed the c...</td>\n",
       "      <td>smu scis alumnus quan heng lim discussed the c...</td>\n",
       "      <td>[(alumnus, None), (quan, a), (heng, n), (lim, ...</td>\n",
       "      <td>alumnus quan heng lim discuss cyber security...</td>\n",
       "      <td>[alumnus, quan, heng, lim, discuss, cyber, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you ever wondered how a website like YouT...</td>\n",
       "      <td>have you ever wondered how a website like yout...</td>\n",
       "      <td>[(ever, r), (wondered, v), (website, n), (yout...</td>\n",
       "      <td>ever wonder website youtube know want e comm...</td>\n",
       "      <td>[ever, wonder, website, youtube, know, want, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past weekend, Whitehat Society (@smuw...</td>\n",
       "      <td>over the past weekend whitehat society smuwhit...</td>\n",
       "      <td>[(past, a), (weekend, n), (whitehat, None), (s...</td>\n",
       "      <td>past weekend whitehat society smuwhitehats o...</td>\n",
       "      <td>[past, weekend, whitehat, society, smuwhitehat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Reposted @smu.libraries ••••• How much do you ...</td>\n",
       "      <td>reposted smu libraries how much do you know ab...</td>\n",
       "      <td>[(reposted, v), (libraries, v), (much, a), (kn...</td>\n",
       "      <td>reposted libraries much know plastic polluti...</td>\n",
       "      <td>[reposted, libraries, much, know, plastic, pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...</td>\n",
       "      <td>since smu s dato kho hui meng career centre an...</td>\n",
       "      <td>[(since, None), (dato, n), (kho, n), (hui, n),...</td>\n",
       "      <td>since dato kho hui meng career centre annual...</td>\n",
       "      <td>[since, dato, kho, hui, meng, career, centre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Using games as part of a mock seminar for Cath...</td>\n",
       "      <td>using games as part of a mock seminar for cath...</td>\n",
       "      <td>[(using, v), (games, n), (part, n), (mock, n),...</td>\n",
       "      <td>use game part mock seminar catholoc junior c...</td>\n",
       "      <td>[use, game, part, mock, seminar, catholoc, jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>At AJC’s University Symposium, Hady fielded fr...</td>\n",
       "      <td>at ajc s university symposium hady fielded fro...</td>\n",
       "      <td>[(ajc, a), (symposium, n), (hady, n), (fielded...</td>\n",
       "      <td>ajc symposium hady field art whether would q...</td>\n",
       "      <td>[ajc, symposium, hady, field, art, whether, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>Getting ready for students at the Education Fa...</td>\n",
       "      <td>getting ready for students at the education fa...</td>\n",
       "      <td>[(getting, v), (ready, a), (students, n), (edu...</td>\n",
       "      <td>get ready student education fair come soon j...</td>\n",
       "      <td>[get, ready, student, education, fair, come, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>It happened one night.\\n#SMUMetamorphosis #smu...</td>\n",
       "      <td>it happened one night smumetamorphosis smusis ...</td>\n",
       "      <td>[(happened, v), (one, None), (night, n), (smum...</td>\n",
       "      <td>happen one night smumetamorphosis freshman g...</td>\n",
       "      <td>[happen, one, night, smumetamorphosis, freshma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>#ComputingatSMU</td>\n",
       "      <td>computingatsmu</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "0     SMU SCIS alumnus Quan Heng Lim discussed the c...   \n",
       "1     Have you ever wondered how a website like YouT...   \n",
       "2     Over the past weekend, Whitehat Society (@smuw...   \n",
       "8     Reposted @smu.libraries ••••• How much do you ...   \n",
       "9     Since 2011, SMU’s Dato’ Kho Hui Meng Career Ce...   \n",
       "...                                                 ...   \n",
       "1040  Using games as part of a mock seminar for Cath...   \n",
       "1041  At AJC’s University Symposium, Hady fielded fr...   \n",
       "1042  Getting ready for students at the Education Fa...   \n",
       "1043  It happened one night.\\n#SMUMetamorphosis #smu...   \n",
       "1044                                    #ComputingatSMU   \n",
       "\n",
       "                                                cleaned  \\\n",
       "0     smu scis alumnus quan heng lim discussed the c...   \n",
       "1     have you ever wondered how a website like yout...   \n",
       "2     over the past weekend whitehat society smuwhit...   \n",
       "8     reposted smu libraries how much do you know ab...   \n",
       "9     since smu s dato kho hui meng career centre an...   \n",
       "...                                                 ...   \n",
       "1040  using games as part of a mock seminar for cath...   \n",
       "1041  at ajc s university symposium hady fielded fro...   \n",
       "1042  getting ready for students at the education fa...   \n",
       "1043  it happened one night smumetamorphosis smusis ...   \n",
       "1044                                     computingatsmu   \n",
       "\n",
       "                                             POS tagged  \\\n",
       "0     [(alumnus, None), (quan, a), (heng, n), (lim, ...   \n",
       "1     [(ever, r), (wondered, v), (website, n), (yout...   \n",
       "2     [(past, a), (weekend, n), (whitehat, None), (s...   \n",
       "8     [(reposted, v), (libraries, v), (much, a), (kn...   \n",
       "9     [(since, None), (dato, n), (kho, n), (hui, n),...   \n",
       "...                                                 ...   \n",
       "1040  [(using, v), (games, n), (part, n), (mock, n),...   \n",
       "1041  [(ajc, a), (symposium, n), (hady, n), (fielded...   \n",
       "1042  [(getting, v), (ready, a), (students, n), (edu...   \n",
       "1043  [(happened, v), (one, None), (night, n), (smum...   \n",
       "1044                                                 []   \n",
       "\n",
       "                                                  Lemma  \\\n",
       "0       alumnus quan heng lim discuss cyber security...   \n",
       "1       ever wonder website youtube know want e comm...   \n",
       "2       past weekend whitehat society smuwhitehats o...   \n",
       "8       reposted libraries much know plastic polluti...   \n",
       "9       since dato kho hui meng career centre annual...   \n",
       "...                                                 ...   \n",
       "1040    use game part mock seminar catholoc junior c...   \n",
       "1041    ajc symposium hady field art whether would q...   \n",
       "1042    get ready student education fair come soon j...   \n",
       "1043    happen one night smumetamorphosis freshman g...   \n",
       "1044                                                      \n",
       "\n",
       "                                           lemma_tokens  \n",
       "0     [alumnus, quan, heng, lim, discuss, cyber, sec...  \n",
       "1     [ever, wonder, website, youtube, know, want, e...  \n",
       "2     [past, weekend, whitehat, society, smuwhitehat...  \n",
       "8     [reposted, libraries, much, know, plastic, pol...  \n",
       "9     [since, dato, kho, hui, meng, career, centre, ...  \n",
       "...                                                 ...  \n",
       "1040  [use, game, part, mock, seminar, catholoc, jun...  \n",
       "1041  [ajc, symposium, hady, field, art, whether, wo...  \n",
       "1042  [get, ready, student, education, fair, come, s...  \n",
       "1043  [happen, one, night, smumetamorphosis, freshma...  \n",
       "1044                                                 []  \n",
       "\n",
       "[504 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    new_text = word_tokenize(text)\n",
    "    return new_text\n",
    "filtered_posts['lemma_tokens'] = filtered_posts['Lemma'].apply(tokenize)\n",
    "filtered_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e5db057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5167\n",
      "2499\n",
      "------ Topic 0 ------\n",
      "technology system read share full team repost need innovation day\n",
      "\n",
      "------ Topic 1 ------\n",
      "smart technology innovation sap city management student article read full\n",
      "\n",
      "------ Topic 2 ------\n",
      "technology innovation data information system student project graduate management learn\n",
      "\n",
      "------ Topic 3 ------\n",
      "technology student time work graduate professor innovation digitaltransformation commencement make\n",
      "\n",
      "------ Topic 4 ------\n",
      "technology ai student law compute information tech professor system make\n",
      "\n",
      "------ Topic 5 ------\n",
      "student swipe smuellipsis reposted information experience share us compute ellipsisinternseries\n",
      "\n",
      "------ Topic 6 ------\n",
      "student technology information programme system law smart learn work compute\n",
      "\n",
      "------ Topic 7 ------\n",
      "team undergraduate learn alumnus full studentlife system student one article\n",
      "\n",
      "------ Topic 8 ------\n",
      "technology system student information innovation business compute share give digitaltransformation\n",
      "\n",
      "------ Topic 9 ------\n",
      "internship learn technology system data information analytics experience work share\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "# Create a id2word dictionary\n",
    "id2word = Dictionary(filtered_posts['lemma_tokens'])\n",
    "print(len(id2word))\n",
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "print(len(id2word))\n",
    "# Creating a corpus object \n",
    "corpus = [id2word.doc2bow(d) for d in filtered_posts['lemma_tokens']]\n",
    "# Instantiating a Base LDA model \n",
    "base_model = LdaMulticore(corpus=corpus, num_topics=10, id2word=id2word, workers=12, passes=5)\n",
    "# Filtering for words \n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in base_model.print_topics()]\n",
    "# Create Topics\n",
    "topics = [' '.join(t[0:10]) for t in words]\n",
    "# Getting the topics\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d56e",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1d4a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "all_text = filtered_posts.Lemma.values.tolist()\n",
    "# clean_text = ' '.join([str[1] for str in str(text).split() if not any(i in str for i in emoji_list)])\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1,1), stop_words = 'english') # You can define your own parameters\n",
    "X = cv.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48b38702",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = (X.T * X) # This is the matrix manipulation step\n",
    "Xc.setdiag(0) # We set the diagonals to be zeroes as it's pointless to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7cdce552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jing_\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "names = cv.get_feature_names() # This are the entity names (i.e. keywords)\n",
    "df = pd.DataFrame(data = Xc.toarray(), columns = names, index = names)\n",
    "df.to_csv('to gephi.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d30ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
